# cryptoData_project
In this project, I developed a cloud-native data pipeline using Azure and Databricks. 
I built an end-to-end data pipeline that ingested live cryptocurrency data from a public API using Python scripts and Azure Blob Storage, processes it through a Bronze-Silver data architecture using Databricks and Delta Lakehouse, and stores the cleaned data in Azure SQL Database. Processing was carried out using unity catalogue and Autolaoder in Databricks and Azure Key vault was configure to manage the Azure SQL Database credentials. Automation/Orchestration was achieved with Azure Data Factory, enabling scalable, reliable and timely analytics-ready data that improves investment decisions and operational efficiency.
